{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configed\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D,Activation, Dropout, Flatten, Dense,Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D  \n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "#config the GPU. If you don't use GPU commen this part\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "set_session(tf.Session(config=config))\n",
    "print('configed')\n",
    "\n",
    "# parameters and data path, save path\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = 'D:\\\\EE628\\\\final_dogs&cats\\\\data\\\\train'\n",
    "validation_data_dir = 'D:\\\\EE628\\\\final_dogs&cats\\\\data\\\\validation'\n",
    "predict_data_dir = 'D:\\\\EE628\\\\final_dogs&cats\\\\data\\\\test'\n",
    "path_folder='D:\\\\EE628\\\\final_dogs&cats\\\\feature\\\\'\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16666 images belonging to 2 classes.\n",
      "Found 8334 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set the image Generator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "features_generator_train = datagen.flow_from_directory(train_data_dir,\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode=None,\n",
    "                                                shuffle=False)\n",
    "features_generator_validation = datagen.flow_from_directory(validation_data_dir,\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode=None,\n",
    "                                                shuffle=False)\n",
    "\n",
    "features_generator_test = datagen.flow_from_directory(predict_data_dir,\n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatures(MODEL,features_generator_train,features_generator_validation,features_generator_test):\n",
    "    input_tensor = Input(shape=(224, 224, 3))  \n",
    "    feature_model = MODEL(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    gen = ImageDataGenerator()\n",
    "    features_train = feature_model.predict_generator(features_generator_train)\n",
    "    features_validation = feature_model.predict_generator(features_generator_validation)\n",
    "    features_test = feature_model.predict_generator(features_generator_test)\n",
    "    print(MODEL,'length of train',len(features_train),'length of validation',len(features_validation))\n",
    "    with h5py.File(path_folder+\"Features_%s.h5\"%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=features_train)\n",
    "        h.create_dataset(\"validation\", data=features_validation)\n",
    "        h.create_dataset(\"test\", data=features_test)\n",
    "        h.create_dataset(\"label_train\", data=features_generator_train.classes)\n",
    "        h.create_dataset(\"label_validation\", data=features_generator_validation.classes)\n",
    "    print(MODEL.__name__,'feature saved')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本来想用5个，最后只用了4个，除去Xception是每次用这个都有memory error，还未解决\n",
    "\n",
    "# Extract features\n",
    "for MODEL in [ResNet50,InceptionV3,VGG19,VGG16]:\n",
    "    ExtractFeatures(MODEL,features_generator_train,features_generator_validation,features_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function VGG16 at 0x0000021B57A199D8> length of train 16666 length of validation 8334\n",
      "VGG16 feature saved\n"
     ]
    }
   ],
   "source": [
    "ExtractFeatures(VGG16,features_generator_train,features_generator_validation,features_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function VGG19 at 0x0000016EFFDB4048> length of train 16666 length of validation 8334\n",
      "VGG19 feature saved\n"
     ]
    }
   ],
   "source": [
    "ExtractFeatures(VGG19,features_generator_train,features_generator_validation,features_generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "try to solve memory error problem\n",
    "import gc\n",
    "\n",
    "\n",
    "def ExtractFeatures_2(MODEL,features_generator_train,features_generator_validation,features_generator_test):\n",
    "    input_tensor = Input(shape=(224, 224, 3))  \n",
    "    feature_model = MODEL(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    with h5py.File(path_folder+\"Features_%s.h5\"%MODEL.__name__) as h:\n",
    "        features_train = feature_model.predict_generator(features_generator_train)\n",
    "        h.create_dataset(\"train\", data=features_train)\n",
    "        del features_train \n",
    "        gc.collect()\n",
    "        \n",
    "        features_validation = feature_model.predict_generator(features_generator_validation)\n",
    "        h.create_dataset(\"validation\", data=features_validation)\n",
    "        del features_validation\n",
    "        gc.collect()\n",
    "        \n",
    "        features_test = feature_model.predict_generator(features_generator_test)\n",
    "        h.create_dataset(\"test\", data=features_test) \n",
    " \n",
    "        del features_test\n",
    "        gc.collect()\n",
    "        h.create_dataset(\"label_train\", data=features_generator_train.classes)\n",
    "        h.create_dataset(\"label_validation\", data=features_generator_validation.classes)\n",
    "    print(MODEL.__name__,'feature saved')\n",
    "ExtractFeatures_2(Xception,features_generator_train,features_generator_validation,features_generator_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
